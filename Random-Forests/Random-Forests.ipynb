{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Code can be found here : https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.08-Random-Forests.ipynb\n",
    "\n",
    "### Edited and Translated to Pyton 3.11.6 By:\n",
    "### Name: Marcel Zama\n",
    "### Student ID: C00260146\n",
    "### Date: 27/11/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display available Matplotlib plot styles\n",
    "print(plt.style.available)  # Print the list of available styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting for Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the plot style to 'seaborn-v0_8-whitegrid'\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Now you can create and display your plots using Matplotlib\n",
    "# For example, you can use the plt.scatter function to create a scatter plot\n",
    "# or other plotting functions as needed for your data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scikit-learn library using pip\n",
    "# If you're running this code in a Jupyter Notebook, use !pip\n",
    "# If you're running it in a script or terminal, use pip directly\n",
    "\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Decision Tree\n",
    "Consider the following two-dimensional data, which has one of four class labels (see the following figure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data with 4 clusters using make_blobs\n",
    "X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Plot the generated data using matplotlib\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Synthetic Data with Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data with 7 clusters using make_blobs\n",
    "X, y = make_blobs(n_samples=3000, centers=7, random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Plot the generated data using matplotlib\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Synthetic Data with 7 Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a decision tree classifier and fit it to the data\n",
    "tree = DecisionTreeClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
    "    # If an axis is not provided, use the current axis\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    \n",
    "    # Adjust axis settings\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Get current axis limits\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # Fit the estimator (model) to the training data\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Create a meshgrid for visualization\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    \n",
    "    # Predict labels for each point in the meshgrid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Create a color plot with the results (decision boundaries)\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, zorder=1)\n",
    "\n",
    "    # Set the axis limits based on the original limits\n",
    "    ax.set(xlim=xlim, ylim=ylim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the visualize_classifier function with the DecisionTreeClassifier model, input data X, and labels y\n",
    "visualize_classifier(DecisionTreeClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers_05_08 is found in the online appendix\n",
    "import helpers_05_08\n",
    "# Call the plot_tree_interactive function with the input data X and labels y\n",
    "helpers_05_08.plot_tree_interactive(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers_05_08 is found in the online appendix\n",
    "import helpers_05_08\n",
    "# Call the randomized_tree_interactive function with the input data X and labels y\n",
    "helpers_05_08.randomized_tree_interactive(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles of Estimators: Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Create a Bagging Classifier with 100 base estimators, using 80% of samples for each estimator\n",
    "bag = BaggingClassifier(base_estimator=tree, n_estimators=100, max_samples=0.8,\n",
    "                        random_state=1)\n",
    "\n",
    "# Fit the Bagging Classifier on the data (assuming X, y are defined earlier)\n",
    "bag.fit(X, y)\n",
    "\n",
    "# Visualize the Bagging Classifier\n",
    "visualize_classifier(bag, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Visualize the RandomForestClassifier\n",
    "visualize_classifier(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression\n",
    "\n",
    "Consider the following data, drawn from the combination of a fast and slow oscillation (see the following figure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generate random data\n",
    "x = 10 * rng.rand(200)\n",
    "\n",
    "# Define a model function with oscillations and noise\n",
    "def model(x, sigma=0.3):\n",
    "    fast_oscillation = np.sin(5 * x)\n",
    "    slow_oscillation = np.sin(0.5 * x)\n",
    "    noise = sigma * rng.randn(len(x))\n",
    "\n",
    "    return slow_oscillation + fast_oscillation + noise\n",
    "\n",
    "# Generate y values using the model\n",
    "y = model(x)\n",
    "\n",
    "# Plot the data points with error bars\n",
    "plt.errorbar(x, y, 0.3, fmt='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the random forest regressor, we can find the best-fit curve as follows (see the following figure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a RandomForestRegressor with 200 trees\n",
    "forest = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "# Fit the model to the data\n",
    "forest.fit(x[:, None], y)\n",
    "\n",
    "# Generate x values for prediction\n",
    "xfit = np.linspace(0, 10, 1000)\n",
    "\n",
    "# Predict y values using the trained model\n",
    "yfit = forest.predict(xfit[:, None])\n",
    "\n",
    "# Generate true y values using the model function\n",
    "ytrue = model(xfit, sigma=0)\n",
    "\n",
    "# Plot the data points with error bars, predicted values, and true values\n",
    "plt.errorbar(x, y, 0.3, fmt='o', alpha=0.5, label='Data')\n",
    "plt.plot(xfit, yfit, '-r', label='Random Forest Prediction')\n",
    "plt.plot(xfit, ytrue, '-k', alpha=0.5, label='True Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display available Matplotlib plot styles\n",
    "print(plt.style.available)  # Print the list of available styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting for Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the plot style to 'seaborn-v0_8-whitegrid'\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Now you can create and display your plots using Matplotlib\n",
    "# For example, you can use the plt.scatter function to create a scatter plot\n",
    "# or other plotting functions as needed for your data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scikit-learn library using pip\n",
    "# If you're running this code in a Jupyter Notebook, use !pip\n",
    "# If you're running it in a script or terminal, use pip directly\n",
    "\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate synthetic data with 4 clusters\n",
    "X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Scatter plot of the generated data\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data with 7 clusters using make_blobs\n",
    "X, y = make_blobs(n_samples=3000, centers=7, random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Plot the generated data using matplotlib\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Synthetic Data with 7 Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a decision tree classifier and fit it to the data\n",
    "tree = DecisionTreeClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
    "    # If an axis is not provided, use the current axis\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    \n",
    "    # Adjust axis settings\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Get current axis limits\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # Fit the estimator (model) to the training data\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Create a meshgrid for visualization\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    \n",
    "    # Predict labels for each point in the meshgrid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Create a color plot with the results (decision boundaries)\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, zorder=1)\n",
    "\n",
    "    # Set the axis limits based on the original limits\n",
    "    ax.set(xlim=xlim, ylim=ylim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the visualize_classifier function with the DecisionTreeClassifier model, input data X, and labels y\n",
    "visualize_classifier(DecisionTreeClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers_05_08 is found in the online appendix\n",
    "import helpers_05_08\n",
    "# Call the plot_tree_interactive function with the input data X and labels y\n",
    "helpers_05_08.plot_tree_interactive(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers_05_08 is found in the online appendix\n",
    "import helpers_05_08\n",
    "# Call the randomized_tree_interactive function with the input data X and labels y\n",
    "helpers_05_08.randomized_tree_interactive(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Create a Bagging Classifier with 100 base estimators, using 80% of samples for each estimator\n",
    "bag = BaggingClassifier(base_estimator=tree, n_estimators=100, max_samples=0.8,\n",
    "                        random_state=1)\n",
    "\n",
    "# Fit the Bagging Classifier on the data (assuming X, y are defined earlier)\n",
    "bag.fit(X, y)\n",
    "\n",
    "# Visualize the Bagging Classifier\n",
    "visualize_classifier(bag, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Visualize the RandomForestClassifier\n",
    "visualize_classifier(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generate random data\n",
    "x = 10 * rng.rand(200)\n",
    "\n",
    "# Define a model function with oscillations and noise\n",
    "def model(x, sigma=0.3):\n",
    "    fast_oscillation = np.sin(5 * x)\n",
    "    slow_oscillation = np.sin(0.5 * x)\n",
    "    noise = sigma * rng.randn(len(x))\n",
    "\n",
    "    return slow_oscillation + fast_oscillation + noise\n",
    "\n",
    "# Generate y values using the model\n",
    "y = model(x)\n",
    "\n",
    "# Plot the data points with error bars\n",
    "plt.errorbar(x, y, 0.3, fmt='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create and fit a RandomForestRegressor\n",
    "forest = RandomForestRegressor(200)\n",
    "forest.fit(x[:, None], y)\n",
    "\n",
    "# Generate x values for plotting\n",
    "xfit = np.linspace(0, 10, 1000)\n",
    "\n",
    "# Predict y values using the trained model\n",
    "yfit = forest.predict(xfit[:, None])\n",
    "\n",
    "# Generate true y values\n",
    "ytrue = model(xfit, sigma=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.errorbar(x, y, 0.3, fmt='o', alpha=0.5)\n",
    "plt.plot(xfit, yfit, '-r')\n",
    "plt.plot(xfit, ytrue, '-k', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Print the keys of the dataset\n",
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the figure\n",
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')\n",
    "    \n",
    "    # label the image with the target value\n",
    "    ax.text(0, 7, str(digits.target[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "# Create a RandomForestClassifier model with 1000 estimators\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "# Make predictions on the test data\n",
    "ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import metrics\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(ypred, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create confusion matrix\n",
    "mat = confusion_matrix(ytest, ypred)\n",
    "\n",
    "# Plot confusion matrix using seaborn heatmap\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d',\n",
    "            cbar=False, cmap='Blues')\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate blobs data with 3000 samples, 4 centers, and a cluster standard deviation of 1.0\n",
    "X, y = make_blobs(n_samples=3000, centers=4, random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Scatter plot of the generated data\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wineQT.csv')  # Replace with your dataset\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "\n",
    "# Create Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  \n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix visualization\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Print the keys of the dataset\n",
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the figure\n",
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')\n",
    "    \n",
    "    # label the image with the target value\n",
    "    ax.text(0, 7, str(digits.target[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "# Create a RandomForestClassifier model\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import metrics\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(ypred, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create confusion matrix\n",
    "mat = confusion_matrix(ytest, ypred)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d',\n",
    "            cbar=False, cmap='Blues')\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create synthetic data using make_blobs\n",
    "X, y = make_blobs(n_samples=3000, centers=4,\n",
    "                  random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Scatter plot of the data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wineQT.csv')  # Replace with your dataset\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Create Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix visualization\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
