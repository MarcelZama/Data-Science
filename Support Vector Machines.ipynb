{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Marcel Zama <br> \n",
    "ID: C00260146 <br> \n",
    "Date: 25/02/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines <br>\n",
    "1. Business Understanding <br>\n",
    "In this Program is being ilustrated the work of Support Vector Machines (SVMs) which are powerful supervised machine learning algorithms used for both classification and regression tasks. In this program, we focus on the classification aspect.<br>\n",
    "SVMs are effective for tasks where we want to classify data points into two or more classes. The main idea behind SVMs is to find the hyperplane that best separates the classes in the feature space. This hyperplane is chosen to maximize the margin between the classes, making it robust to new, unseen data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of SVMs used in the Program:\n",
    "In this program, we are using the SVC implementation of SVMs, which stands for Support Vector Classification. SVC is designed for classification tasks and is particularly versatile due to its ability to use different kernel functions.<br>\n",
    "Kernel Functions:<br>\n",
    "- A key feature of SVMs is the use of kernel functions, which map the input data into higher-dimensional spaces.<br>\n",
    "- The kernel parameter in the SVC implementation allows us to specify different kernel functions. In this program, we use the 'rbf' (radial basis function) kernel.<br>\n",
    "- The 'rbf' kernel is commonly used and is effective for non-linear classification tasks. It allows SVMs to learn complex decision boundaries that can better separate classes that are not linearly separable in the original feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVMs) are effective in the following scenarios:<br>\n",
    "\n",
    "1. Binary Classification: SVMs are primarily used for binary classification tasks, where the goal is to classify data into two classes, such as spam vs. non-spam emails, fraudulent vs. non-fraudulent transactions, or cancerous vs. non-cancerous tumors.<br>\n",
    "\n",
    "2. Linearly Separable Data: SVMs work well when the data is linearly separable, meaning the classes can be separated by a straight line (in 2D), a plane (in 3D), or a hyperplane (in higher dimensions). SVMs aim to find the hyperplane that best separates the classes with the maximum margin.<br>\n",
    "\n",
    "3. High-Dimensional Space: SVMs are effective in high-dimensional spaces, such as text classification and image classification tasks, where each feature represents a different dimension.<br>\n",
    "\n",
    "4. Small to Medium-Sized Datasets: SVMs can handle small to medium-sized datasets efficiently. They are memory efficient and do not require a lot of training data to perform well.<br>\n",
    "\n",
    "5. Data with Non-Linear Separability: SVMs can also handle non-linear data by using different kernel tricks such as polynomial kernel, radial basis function (RBF) kernel, or sigmoid kernel. These kernels allow SVMs to map the input features into a higher-dimensional space where the classes become linearly separable.<br>\n",
    "\n",
    "6. When Regularization is Needed: SVMs have a regularization parameter (C) that helps control overfitting. When the dataset has noise or outliers, SVMs with appropriate C values can generalize well and avoid overfitting.<br>\n",
    "\n",
    "7. Image Recognition: SVMs have been successfully used in image recognition tasks, such as handwriting recognition, object detection, and face detection.<br>\n",
    "\n",
    "8. Text and Document Classification: SVMs are popular for text classification tasks, such as sentiment analysis, spam detection, and topic categorization. They can efficiently handle large feature spaces and sparse data.<br>\n",
    "\n",
    "9. Medical Diagnosis: SVMs can be used in medical diagnosis to predict diseases based on patient data, such as symptoms, test results, and patient history.<br>\n",
    "\n",
    "10. When Interpretability is Not the Top Priority: SVMs can be complex models, especially when using non-linear kernels. While they provide high accuracy, the decision boundary can be difficult to interpret.<br>\n",
    "\n",
    "11. When Robust Generalization is Required: SVMs aim to maximize the margin between classes, which leads to better generalization on unseen data. They tend to perform well in practice when properly tuned.<br>\n",
    "\n",
    "In summary, Support Vector Machines (SVMs) are a good choice when dealing with binary classification problems, linearly separable data, high-dimensional spaces, and when a good generalization performance is desired. They are particularly effective when the dataset is small to medium-sized and when the data can be separated by a clear margin. SVMs also shine in scenarios where data has a non-linear relationship, and various kernel tricks can be applied to map the data into higher-dimensional spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Breast Cancer Wisconsin (Diagnostic) dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the types of data\n",
    "print(\"Data types:\")\n",
    "print(\"X - Features (first 5 rows):\")\n",
    "print(pd.DataFrame(X, columns=cancer.feature_names).head())\n",
    "print(\"\\ny - Target (first 5 rows):\")\n",
    "print(pd.DataFrame(y, columns=[\"Target\"]).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:<br>\n",
    "- Accuracy: The overall accuracy of the SVM model on the test set is printed at the end.<br>\n",
    "- Classification Report:<br>\n",
    " - Precision: Indicates the proportion of correctly predicted positive instances out of all predicted positives.<br>\n",
    " - Recall: Indicates the proportion of correctly predicted positive instances out of all actual positives.<br>\n",
    " - F1-score: The harmonic mean of precision and recall, providing a balance between the two.<br>\n",
    " - Support: The number of actual occurrences of the class in the dataset.<br>\n",
    "- Confusion Matrix:<br>\n",
    " - The diagonal elements represent the number of correct predictions for each class.<br>\n",
    " - Off-diagonal elements represent misclassifications.<br>\n",
    " - The heatmap helps visualize the distribution of correct and incorrect predictions.<br><br>\n",
    " By analyzing the classification report and confusion matrix, we can gain insights into how well the SVM model is performing in classifying breast cancer diagnoses (Malignant or Benign) based on the given features. The confusion matrix allows us to identify any specific areas where the model may be making more errors, such as false positives or false negatives.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MarkDown:\n",
    "In order for the algorithm to work following commands have to be executed.<br> \n",
    "*pip install numpy*<br> \n",
    "*pip install pandas*<br> \n",
    "*pip install scikit-learn*<br> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
